# 基于Milvus的RAG系统

本项目是一个使用Milvus实现向量和文本检索的RAG系统，基于SpringCloud和kubernetes实现，致力于实现一个高效、稳定、通用的RAG系统。

## 系统功能介绍

完整的RAG系统主要流程如下：

+ **数据准备阶段**：数据提取——>数据处理——>数据入库

+ **应用阶段**：用户提问——>数据检索（召回）——>注入Prompt——>LLM生成答案

完整的流程图如下：

![image-20250428201218900](%E4%BB%8B%E7%BB%8D.assets/image-20250428201218900.png)

# 系统架构

![image-20250429011331812](%E4%BB%8B%E7%BB%8D.assets/image-20250429011331812.png)

**下面对系统的主要模块进行介绍：**

## **数据加载模块**（Producer模块）

对于数据的加载和处理，如果采用基础的文件处理，存在以下问题：

+ 单个运行的机器挂掉或者发生错误，文档的数据没有完全加载，极易出现信息丢失或者重复，不能保证信息的完整性和一致性。
+ 如果需要短时间内对大文件进行向量化处理，采用单点方式无法满足时间需求。

所以本系统使用Kafka来处理这些数据。当收到创建知识库请求时，创建一个任务去使用Kafka Producer来加载数据，使用Kafka Consumer来消费数据。

**数据一致性保证**

1. 掉线保护

   使用Redis记录读取到当前文件的位置，如果当前节点掉线，新的节点会从之前读取到的位置，继续进行读取。在这期间产生的少量重复数据依靠幂等性来保证一致。

2. 消费保护

   在消费数据后再对offset进行提交，保证数据不丢失。

3. 性能提升

   根据性能需求，对Topic进行分片，使用消费者组进行并行消费，保证数据处理的性能需求。

## **文件处理模块**（Consumer模块）

### 文本分割

文本分割主要考虑两个因素：1. embedding模型的Tokens限制情况；2. 语义完整性对整体的检索效果的影响。

由于不同分割方式对分割后语义影响很大，为了保证分片的语义，选择混合分块算法。

1. 优先尝试按 `\n\n` (段落) 分割，如果分割后的块仍然太大，再尝试按 `\n` (换行符) 分割。
2. 当分割后的大小仍然大于分块大小，使用句子分割算法将文本分割成独立的句子，块之间引入句子级别的重叠。
3. 如果一个句子还是大于分块大小，就按照固定的字符数分割。
4. 使用Small-to-Big 检索优化，在分片数据中添加bigId字段，维护小块和父块之间的映射关系。根据需要可以返回父块的数据，提高模型回复的质量。

## **向量化**（embedding模块）

调用向量化模块，使用系统提供的向量化模型，本系统提供m3e模型进行向量化，主要流程如下：

1. 使用模型提供的分词器（`tokenizer.json`）对传入的数据转换为模型训练时的token
2. 将处理好的数据转换为模型处理的数据格式（`NDList`）
3. 对模型生成的数据进行处理（转换float数组，归一化处理）
4. 使用单例模式，防止模型或者文件重复加载

本系统使用模块化设计，可以对模型进行选择和更新，也可以接入外部模型进行向量化。

### 索引选择

Milvus主要提供了FLAT，HNSW，IVF这三种索引类型：

FLAT：对数据库的向量进行穷举，在大数据集的情况下内存占用率很高，只有在数据集较小的情况考虑。

HNSW：基本思想是使用一种层次化的图结构，每一层都是一个导航小世界图，从而实现了在高维空间中的高效搜索，这种索引方式在通用检索场景上有显著的优势。但是该算法在高过滤比下性能会有折损，因为如果标量查询条件过多，可能触发很多次回溯才能达到查找需求。

IVF：将高维向量空间分为多个簇，每个簇对应一个倒排列表，存储了属于该簇的向量索引。为了保证检索性能需要将其全量加载到内存中，从而占用了大量的内存空间，容易造成内存资源瓶颈。

所以说，根据标量查询条件是否复杂选择HNSW或者IVF索引。如果查询标量条件较少，可以选择HNSW；如果查询条件过多，选择IVF，但是需要对IVF的内存占用进行优化。

## 集成Milvus数据库

为了优化Milvus的连接，本系统使用了`apache commons pool2`管理milvus的连接，优点如下：

1. 复用连接对象，加快查询和插入数据的速度，不必每次都去建立连接
2. 由于Milvus集群架构，可以根据查询节点的个数动态修改连接池的数量，提高查询性能

对于全文检索的实现，Milvus 2.5 内置了基于稀疏向量的 BM25 检索机制，milvus会自动完成分词、停用词过滤和稀疏向量生成。

## 查询模块（Search模块）

在收到问题时，主要是对问题进行向量查询和全文检索。以下是本系统的查询流程：

### 问题分析

对问题进行NLP分析，分析问题**语义查询**还是**精确查询**，得到问题意图的比例值，根据这个比例决定两种查询结果的数量，实现语义检索和全文检索的融合。

### 多路查询和结果合并

由于在多库查询的过程中，同步IO阻塞时间会累加，这回导致查询时间变得非常长。所以使用多线程技术（CompletableFuture）进行并行查询。

### 清理和去重

对于每个库的查询结果，首先进行清理和结果合并。

首先对于查询的结果进行清洗，如果结果的质量太差，例如字符数量小于20，就删除这个结果。

然后是结果去重，由于之前在存入时记录了父文档的索引，也就是全文检索库的索引。基于索引对结果进行合并，如果向量结果的索引在父文档中出现，就删除向量结果，并且提高父文档的相关度。如果多个向量结果父文档索引（bigId）相同，把这几个结果合并为父文档。还可以根据需要，直接将向量结果转换为父文档。

### 多路结果合并

对于所有库的文档：

使用 RRF（多路召回倒数排序算法）进行结果集的合并，大致原理如下：

每个文档按它在单个列表中的排名，加权打分。得到这个结果的基础分。

对每个结果维护一个用户分，在用户对这个数据进行点赞/点踩之后，更新这个值。查询这个用户分。

根据需要，加入自己需要的结果的分数，本系统使用了新闻数据集，所以加入了时间分数。计算每个文档距离今天的天数，然后把天数归一化成 0 ~ 1 之间的小数。

最后算出每个文档的最终得分，最后按照得分倒序排序，再截取需要的结果个数，就拿到了需要的结果。

如果合并的结果集很大，单线程处理会很慢，所以使用多线程分块处理，每100个文档分配为一个任务，然后使用多个线程处理。

### 结果缓存机制

使用Redis对结果进行缓存，但是如果对于每个问题的文档都去缓存结果，当问题很多的情况，会占用很多的内存。所以需要对缓存机制进行优化。

针对每次查询的结果进行分析：一个问题的结果对应着很多文档。

可以提取这些文档的ID列表，由于这些列表占用内存很小，直接使用Redis的List存储这个问题对应的ID列表。

对于查询出来的文档列表，由于多个问题对应的文档可能相同，所以在Redis中根据文档ID作为key去存储，避免重复存储一个文档，造成浪费。对于大量文档可能造成的内存占用问题，使用LRU思想进行解决。

在Redis中维护一个zset，用访问时间作为score。每次查询或者访问到一个文档时，根据这个文档ID和当前时间去更新zset。如果zset大小大于规定大小，就在Redis删除score最小（也就是最旧）的文档。

在查询时，使用AOP拦截方法，先在Redis查询ID列表，如果查询成功，再根据ID列表在Redis查询文档，如果这个ID在Redis中不存在，就去Milvus中查询。如果查询失败，就去执行原来的查询逻辑。

## 日志记录模块

检索性能记录：在Common（公共包）中使用AOP在Milvus调用方法的日志并且生成结构化日志，对Milvus查询性能指标进行收集和分析。

用户行为记录：由于所有的请求都是从GateWay（网关）进来，所以在网关进行用户行为日志记录，并且对调用链路进行追踪。

**下面对系统架构进行介绍**：

由于本系统分多个模块，模块之间需要进行调用，每个模块都需要根据处理数据大小进行扩缩容，所以采用了SpringCloud+kubernetes实现。

### 模块调用

集成openfeign RPC接口调用、loadbalancer负载均衡。

### 服务发现

一般的服务发现基于注册中心实现，但是Kubernetes内部使用etcd管理Pod，并且提供service管理一组相同功能的节点。所以本项目使用Kubernetes服务发现替代传统SpringCloud服务发现，避免冗余。

 ![image-20250429010442831](%E4%BB%8B%E7%BB%8D.assets/image-20250429010442831.png)

 <img src="%E4%BB%8B%E7%BB%8D.assets/image-20250429010540282.png" alt="image-20250429010540282" style="zoom: 80%;" />

### 节点扩缩容

使用Deployment动态管理节点数量，支持节点动态扩缩容，提高系统吞吐量

 ![image-20250429010822233](%E4%BB%8B%E7%BB%8D.assets/image-20250429010822233.png)

 ![image-20250429011045159](%E4%BB%8B%E7%BB%8D.assets/image-20250429011045159.png)

# 优化建议

1. IVF索引向量查询使用GPU实现，需要考虑多标量过滤查询时，优化查询时占用资源
2. 性能日志系统智能分析系统，与Kubernetes结合，实现智能动态扩缩容
3. 根据用户行为优化评分系统，不只是依赖于用户评分



